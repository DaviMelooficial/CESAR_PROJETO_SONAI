# Sistema de AnÃ¡lise e VisualizaÃ§Ã£o de RelatÃ³rios - Fluxograma Completo

## VisÃ£o Geral do Projeto

Este documento descreve o fluxo completo do sistema de anÃ¡lise e visualizaÃ§Ã£o de relatÃ³rios da MC Sonae, desde a extraÃ§Ã£o de dados de mÃºltiplos formatos atÃ© a apresentaÃ§Ã£o final em dashboard interativo.

## Arquitetura do Sistema

```mermaid
graph TD
    A[Documentos de Origem] --> B[Sistema de ExtraÃ§Ã£o]
    B --> C[Dados Processados]
    C --> D[Jupyter Notebook - EDA]
    D --> E[Insights e AnÃ¡lises]
    E --> F[Dashboard Streamlit]
    F --> G[UsuÃ¡rio Final]
    
    A1[PDF] --> B
    A2[DOC/DOCX] --> B
    A3[CSV] --> B
    A4[XLSX] --> B
    
    B1[extrator_pdf.py] --> C
    B2[extrator_doc.py] --> C
    B3[extrator_csv_xlsx.py] --> C
    B4[extrator_principal.py] --> C
    
    C1[JSON] --> D
    C2[CSV] --> D
    C3[TXT] --> D
```

## Fluxograma Detalhado

### 1. Camada de Dados de Origem ğŸ“

**LocalizaÃ§Ã£o**: `data/raw/`

#### Tipos de Arquivos Suportados:
- **PDF**: RelatÃ³rios executivos, documentos corporativos
- **DOC/DOCX**: Atas de reuniÃ£o, relatÃ³rios departamentais
- **CSV**: Dados tabulares, mÃ©tricas de projetos
- **XLSX**: Planilhas complexas, dashboards financeiros

#### Exemplo de Estrutura:
```
data/raw/
â”œâ”€â”€ Relatorio_projetos.csv
â”œâ”€â”€ RELATÃ“RIO DE PROJETOS 2024.pdf
â”œâ”€â”€ Exemplo_doc.docx
â””â”€â”€ outros_documentos/
```

### 2. Sistema de ExtraÃ§Ã£o ğŸ”§

#### 2.1 Extratores Especializados

##### **extrator_pdf.py**
```python
# Funcionalidades:
- PyPDF2: ExtraÃ§Ã£o bÃ¡sica de texto
- pdfplumber: ExtraÃ§Ã£o avanÃ§ada + tabelas
- Metadados: Autor, data criaÃ§Ã£o, nÃºmero pÃ¡ginas
- Fallback automÃ¡tico entre bibliotecas
```

**SaÃ­das**:
- Texto completo estruturado
- Tabelas extraÃ­das (se existirem)
- Metadados do documento

##### **extrator_doc.py**
```python
# Funcionalidades:
- python-docx: Processamento DOCX
- zipfile: MÃ©todo alternativo XML
- ExtraÃ§Ã£o de parÃ¡grafos numerados
- PreservaÃ§Ã£o de estilos
```

**SaÃ­das**:
- ParÃ¡grafos estruturados
- Tabelas incorporadas
- Metadados de autoria

##### **extrator_csv_xlsx.py**
```python
# Funcionalidades:
- pandas: AnÃ¡lise robusta de dados
- DetecÃ§Ã£o automÃ¡tica de encoding
- EstatÃ­sticas descritivas
- ValidaÃ§Ã£o de qualidade
```

**SaÃ­das**:
- Dados estruturados em JSON
- Metadados estatÃ­sticos
- AnÃ¡lise de qualidade

#### 2.2 Orquestrador Principal

##### **extrator_principal.py**
```python
# Funcionalidades:
- Interface unificada CLI/interativa
- Processamento em lote
- RelatÃ³rios de execuÃ§Ã£o
- Tratamento de erros robusto
```

**Comando de ExecuÃ§Ã£o**:
```bash
python extrator_principal.py --todos --formato json
```

### 3. Camada de Dados Processados ğŸ“Š

**LocalizaÃ§Ã£o**: `data/processed/`

#### Estrutura de SaÃ­da:
```
data/processed/
â”œâ”€â”€ Relatorio_projetos_dados.json
â”œâ”€â”€ RELATÃ“RIO DE PROJETOS 2024_dados.json
â”œâ”€â”€ Exemplo_doc_dados.json
â””â”€â”€ metadados/
    â”œâ”€â”€ logs_execucao.txt
    â””â”€â”€ relatorio_processamento.txt
```

#### Formato JSON PadrÃ£o:
```json
{
  "dados": [...],
  "metadados": {
    "encoding": "utf-8",
    "num_linhas": 4,
    "tamanho_arquivo": 681,
    "data_processamento": "2024-10-11"
  },
  "estatisticas": {...},
  "qualidade": {
    "completude": 100,
    "consistencia": "alta"
  }
}
```

### 4. AnÃ¡lise ExploratÃ³ria (Jupyter Notebook) ğŸ“ˆ

**Arquivo**: `notebooks/analise.ipynb`

#### Etapas da AnÃ¡lise:

##### 4.1 PreparaÃ§Ã£o dos Dados
```python
# Carregamento e limpeza
df = pd.read_csv('../data/processed/dados_consolidados.csv')
df['Data_Inicio'] = pd.to_datetime(df['Data_Inicio'])
df['Duracao_meses'] = (df['Data_Fim'] - df['Data_Inicio']).dt.days / 30.44
```

##### 4.2 AnÃ¡lise Univariada
- DistribuiÃ§Ã£o de investimentos
- Status dos projetos
- CategorizaÃ§Ã£o por departamento
- MÃ©tricas de duraÃ§Ã£o

##### 4.3 AnÃ¡lise Bivariada
- CorrelaÃ§Ã£o investimento vs progresso
- RelaÃ§Ã£o duraÃ§Ã£o vs performance
- AnÃ¡lise temporal (Gantt)
- EficiÃªncia departamental

##### 4.4 Insights e Storytelling
- Dashboard executivo
- Ranking de performance
- RecomendaÃ§Ãµes estratÃ©gicas
- LimitaÃ§Ãµes e estudos futuros

#### Outputs da AnÃ¡lise:
```python
# MÃ©tricas Calculadas:
- ROI_Progresso = Progresso(%) / (Investimento/1000)
- Eficiencia_Departamental = Progresso_Medio / Investimento_Total
- Correlacao_Investimento_Progresso = 0.803
- Taxa_Conclusao = 25%
```

### 6. Fluxo de ExecuÃ§Ã£o Completo ğŸ”„

#### 6.1 Pipeline de Dados

```bash
# 1. ExtraÃ§Ã£o de dados
cd scripts/
python extrator_principal.py --todos --formato json

# 2. AnÃ¡lise exploratÃ³ria
cd ../notebooks/
jupyter notebook analise.ipynb

# 3. Dashboard
cd ../dashboard/
streamlit run app.py
```

#### 6.2 AutomaÃ§Ã£o com Scripts

**Arquivo**: `run_pipeline.py`
```python
import subprocess
import logging
from datetime import datetime

def run_extraction():
    """Executa extraÃ§Ã£o de dados"""
    result = subprocess.run([
        'python', 'scripts/extrator_principal.py', 
        '--todos', '--formato', 'json'
    ])
    return result.returncode == 0

def update_dashboard_data():
    """Atualiza dados para dashboard"""
    # Consolidar JSONs em formato dashboard
    consolidated_data = merge_extracted_data()
    save_dashboard_data(consolidated_data)

def main():
    if run_extraction():
        update_dashboard_data()
        print("Pipeline executado com sucesso!")
    else:
        print("Erro na extraÃ§Ã£o de dados")
```

### 7. Estrutura de Arquivos Final ğŸ“‚

```
project_eda2/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                    # Dados originais
â”‚   â”œâ”€â”€ processed/              # Dados extraÃ­dos
â”‚   â””â”€â”€ dashboard/              # Dados para dashboard
â”œâ”€â”€ scripts/                    # Sistema de extraÃ§Ã£o
â”œâ”€â”€ notebooks/                  # AnÃ¡lise exploratÃ³ria
â”œâ”€â”€ dashboard/                  # AplicaÃ§Ã£o Streamlit
â”‚   â”œâ”€â”€ app.py
â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â”œâ”€â”€ charts.py
â”‚   â”‚   â”œâ”€â”€ metrics.py
â”‚   â”‚   â””â”€â”€ filters.py
â”‚   â””â”€â”€ utils/
â”‚       â”œâ”€â”€ data_loader.py
â”‚       â””â”€â”€ calculations.py
â”œâ”€â”€ config/                     # ConfiguraÃ§Ãµes
â”œâ”€â”€ logs/                       # Logs de execuÃ§Ã£o
â””â”€â”€ docs/                       # DocumentaÃ§Ã£o
```

### 8. ConsideraÃ§Ãµes TÃ©cnicas ğŸ› ï¸

#### 8.1 Performance
- Cache de dados com `@st.cache_data`
- Lazy loading para datasets grandes
- OtimizaÃ§Ã£o de queries para filtros

#### 8.2 SeguranÃ§a
- ValidaÃ§Ã£o de inputs
- SanitizaÃ§Ã£o de dados
- Controle de acesso por usuÃ¡rio

#### 8.3 Escalabilidade
- ModularizaÃ§Ã£o do cÃ³digo
- ConfiguraÃ§Ã£o via variÃ¡veis de ambiente
- Suporte a mÃºltiplas fontes de dados

### 9. Roadmap de ImplementaÃ§Ã£o ğŸ“…

#### Fase 1: MVP (2 semanas)
- [ ] Dashboard bÃ¡sico com mÃ©tricas principais
- [ ] IntegraÃ§Ã£o com dados extraÃ­dos
- [ ] VisualizaÃ§Ãµes core (barras, pizza, linha)

#### Fase 2: Funcionalidades AvanÃ§adas (3 semanas)
- [ ] Filtros dinÃ¢micos
- [ ] ExportaÃ§Ã£o de relatÃ³rios
- [ ] Sistema de alertas

#### Fase 3: OtimizaÃ§Ã£o (2 semanas)
- [ ] Performance tuning
- [ ] Testes automatizados
- [ ] DocumentaÃ§Ã£o completa

### 10. MÃ©tricas de Sucesso ğŸ“Š

#### KPIs do Sistema:
- **Tempo de processamento**: < 30 segundos
- **Uptime do dashboard**: > 99%
- **PrecisÃ£o da extraÃ§Ã£o**: > 95%
- **SatisfaÃ§Ã£o do usuÃ¡rio**: > 8/10

#### MÃ©tricas de NegÃ³cio:
- **ReduÃ§Ã£o tempo anÃ¡lise**: 70%
- **Aumento insights**: 3x mais descobertas
- **ROI do projeto**: Positivo em 6 meses

---

*Este documento serve como guia tÃ©cnico para implementaÃ§Ã£o e manutenÃ§Ã£o do sistema de anÃ¡lise de relatÃ³rios corporativos.*
